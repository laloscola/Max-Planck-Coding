{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cdf1167-73c7-4754-b4c6-92493092b262",
   "metadata": {},
   "source": [
    "### MCP PMT Measurement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9abd4e1a-d0df-4649-a597-1fe5c090d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pandas as pd \n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37808167-3469-4a10-8430-0f5125cc36f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_MCPPMT/MCP_PMT_10min_Run815_list2.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata_MCPPMT/MCP_PMT_10min_Run815_list2.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/physics/lib/python3.12/site-packages/pandas/io/parquet.py:669\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    666\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    667\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/physics/lib/python3.12/site-packages/pandas/io/parquet.py:258\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    257\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    265\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    266\u001b[39m         path_or_handle,\n\u001b[32m    267\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m         **kwargs,\n\u001b[32m    271\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/physics/lib/python3.12/site-packages/pandas/io/parquet.py:141\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    131\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    134\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/physics/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data_MCPPMT/MCP_PMT_10min_Run815_list2.parquet'"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('data_MCPPMT/MCP_PMT_10min_Run815_list2.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95938e48-a225-467f-87e4-676af41c3d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_full_hists(file_path, tot_range=(0.001, 5), delta_range=(0, 20), batch_size = 500_000, num_bins=1000, columns = ('Tstamp_us', 'Ch', 'ToA_ns', 'ToT_ns')):\n",
    "    \n",
    "    pf = pq.ParquetFile(file_path)\n",
    "    it = pf.iter_batches(batch_size = batch_size, columns=columns)\n",
    "    \n",
    "    # bins and widths once\n",
    "    bin_edges_tot   = np.linspace(tot_range[0], tot_range[1], num_bins + 1)     # shared ToT bins \n",
    "    bin_edges_delta = np.linspace(delta_range[0], delta_range[1], num_bins + 1) # shared delta bins \n",
    "    w_tot   = np.diff(bin_edges_tot)     # ToT bin widths\n",
    "    w_delta = np.diff(bin_edges_delta)   # delta bin widths \n",
    "    \n",
    "    # accumulators\n",
    "    hist_MCP_tot = np.zeros(num_bins, dtype=int)      # counts \n",
    "    hist_MCP_delta = np.zeros(num_bins, dtype=int)    # counts \n",
    "    hist_HPD_tot = np.zeros(num_bins, dtype=int)      # counts \n",
    "    hist_HPD_delta = np.zeros(num_bins, dtype=int)    # counts \n",
    "    hist_trig_tot = np.zeros(num_bins, dtype=int)      # counts \n",
    "    hist_trig_delta = np.zeros(num_bins, dtype=int)    # counts \n",
    "    \n",
    "    it = pf.iter_batches(batch_size = 500_000, columns=None)\n",
    "    \n",
    "    print('Accumulating Histograms...')\n",
    "    for i, batch in enumerate(it):\n",
    "        # print(f'Processing batch {i}...')\n",
    "        # print(batch)\n",
    "        # mask = (pc.field('ToA_ns') >= delta_range[0]) & (pc.field('ToA_ns') <= delta_range[1])  # maybe add: & (pc.field('ToT_ns') != 0) & (pc.field('Entries') == 2)\n",
    "    \n",
    "        # splitting into Channels\n",
    "        mask_MCP = pc.equal(batch[\"Ch\"], 9) \n",
    "        pf_MCP = batch.filter(mask_MCP)\n",
    "        mask_HPD = pc.equal(batch[\"Ch\"], 8)\n",
    "        pf_HPD = batch.filter(mask_HPD)\n",
    "        mask_trig = pc.equal(batch['Ch'], 0)\n",
    "        pf_trig = batch.filter(mask_trig)\n",
    "        \n",
    "        if pf_MCP.num_rows > 0: \n",
    "            df_MCP = pf_MCP.to_pandas()\n",
    "            if 'ToT_ns' in df_MCP:   \n",
    "                h, _ = np.histogram(df_MCP['ToT_ns'].dropna(), bins=bin_edges_tot)  # ToT\n",
    "                hist_MCP_tot += h  # accumulate \n",
    "            if 'ToA_ns' in df_MCP:\n",
    "                h, _ = np.histogram(df_MCP[\"ToA_ns\"].dropna(), bins=bin_edges_delta) # delta \n",
    "                hist_MCP_delta += h  # accumulate\n",
    "    \n",
    "        if pf_HPD.num_rows > 0: \n",
    "            df_HPD = pf_HPD.to_pandas()\n",
    "            if 'ToT_ns' in df_HPD:   \n",
    "                h, _ = np.histogram(df_HPD['ToT_ns'].dropna(), bins=bin_edges_tot)  # ToT\n",
    "                hist_HPD_tot += h  # accumulate \n",
    "            if 'ToA_ns' in df_HPD:\n",
    "                h, _ = np.histogram(df_HPD[\"ToA_ns\"].dropna(), bins=bin_edges_delta) # delta \n",
    "                hist_HPD_delta += h  # accumulate\n",
    "    \n",
    "        if pf_trig.num_rows > 0:\n",
    "            df_trig = pf_trig.to_pandas()\n",
    "            if 'ToT_ns' in df_trig:   \n",
    "                h, _ = np.histogram(df_trig['ToT_ns'].dropna(), bins=bin_edges_tot)  # ToT\n",
    "                hist_trig_tot += h  # accumulate \n",
    "            if 'ToA_ns' in df_trig:\n",
    "                h, _ = np.histogram(df_trig[\"ToA_ns\"].dropna(), bins=bin_edges_delta) # delta \n",
    "                hist_trig_delta += h  # accumulate\n",
    "    \n",
    "    \n",
    "    centers_delta = 0.5 * (bin_edges_delta[:-1] + bin_edges_delta[1:])           # centers \n",
    "    centers_tot   = 0.5 * (bin_edges_tot[:-1] + bin_edges_tot[1:])               # centers \n",
    "\n",
    "def plot_full(centers_tot, bin_edges_tot, centers_delta, bin_edges_delta,\n",
    "            hist_MCP_tot, hist_HPD_tot, hist_trig_tot,\n",
    "            hist_MCP_delta, hist_HPD_delta, hist_trig_delta):\n",
    "    plt.style.use('ggplot')\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Left: ToT histograms\n",
    "    axs[0].hist(\n",
    "        [centers_tot, centers_tot],\n",
    "        bins=bin_edges_tot,\n",
    "        weights=[hist_MCP_tot, hist_HPD_tot], # insert: hist_trig_tot here to display trigger data\n",
    "        histtype=\"step\",\n",
    "        linewidth=1,\n",
    "        label=[\"MCP\", \"HPD\", \"Trigger\"],\n",
    "    )\n",
    "    axs[0].set_title(\"ToT counts\")\n",
    "    axs[0].set_xlabel(\"ToT ns\")\n",
    "    axs[0].set_ylabel(\"Count\")\n",
    "    axs[0].legend()\n",
    "    \n",
    "    # fig.delaxes(axs[0]) # deselect here to display ToT data\n",
    "    \n",
    "    # Right: ToA histograms \n",
    "    axs[1].hist(\n",
    "        [centers_delta, centers_delta], \n",
    "        bins=bin_edges_delta,\n",
    "        weights=[hist_MCP_delta, hist_HPD_delta],\n",
    "        histtype=\"step\",\n",
    "        linewidth=1,\n",
    "        label=[\"MCP\", \"HPD\", \"trigger\"],\n",
    "    )\n",
    "    axs[1].set_title(\"ToA counts\")\n",
    "    axs[1].set_xlabel(\"ToA ns\")\n",
    "    axs[1].set_ylabel(\"Count\")\n",
    "    axs[1].legend()\n",
    "    \n",
    "    # comment: there are too few ToA datapoints for the Trigger (which makes sense) to display \n",
    "    # comment: in the ToT data we see a delta peak at ~ 3.2ns ,this is probably not physical (one sees this when comparing to trigger data), might just be what the TDC does when reaching its upper limit\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    return (centers_tot, bin_edges_tot, centers_delta, bin_edges_delta,\n",
    "            hist_MCP_tot, hist_HPD_tot, hist_trig_tot,\n",
    "            hist_MCP_delta, hist_HPD_delta, hist_trig_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58616ec-8a39-43b0-be0e-b741346356df",
   "metadata": {},
   "source": [
    "### now add the Gauss fit to calculate FWMH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eec1e4cb-560d-46cb-b4a6-d26c76501db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x, A, mu, sigma):\n",
    "    return A * np.exp(-(x - mu)**2 / (2.0 * sigma**2))\n",
    "\n",
    "def fit_peak(centers, counts, around_mu=None, halfwidth=None):\n",
    "    # pick default region around max if not given\n",
    "    if around_mu is None:\n",
    "        i_max = np.argmax(counts)\n",
    "        around_mu = centers[i_max]\n",
    "    if halfwidth is None:\n",
    "        halfwidth = 1.0  # ns, adjust to your resolution\n",
    "    mask = (centers >= around_mu - halfwidth) & (centers <= around_mu + halfwidth)\n",
    "    x = centers[mask]\n",
    "    y = counts[mask]\n",
    "    if x.size < 5 or y.max() == 0:\n",
    "        return None\n",
    "    A0 = y.max()\n",
    "    mu0 = x[y.argmax()]\n",
    "    # crude sigma guess: halfwidth/2\n",
    "    sig0 = max(halfwidth/2.0, (x[1]-x[0]) * 2.0)\n",
    "    try:\n",
    "        popt, pcov = curve_fit(gauss, x, y, p0=[A0, mu0, sig0], maxfev=10000)\n",
    "        A, mu, sigma = popt\n",
    "        fwhm = 2.35482004503 * abs(sigma)\n",
    "        return dict(A=A, mu=mu, sigma=abs(sigma), fwhm=fwhm, x=x, y=y, cov=pcov)\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faefca6c-162a-437f-815c-e9de0ebba1af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist_MCP_delta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot_FWHM_analysis\u001b[39m(hist_MCP_delta\u001b[38;5;241m=\u001b[39m\u001b[43mhist_MCP_delta\u001b[49m, hist_HPD_delta\u001b[38;5;241m=\u001b[39mhist_HPD_delta, fit_MCP\u001b[38;5;241m=\u001b[39mfit_MCP, fit_HPD\u001b[38;5;241m=\u001b[39mfit_HPD):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# 2) Zoomed delta peaks with fits\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     fig2, axs2 \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax, counts, title, fit \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m      5\u001b[0m         (axs2[\u001b[38;5;241m0\u001b[39m], hist_MCP_delta, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMCP delta peak\u001b[39m\u001b[38;5;124m\"\u001b[39m, fit_MCP),\n\u001b[1;32m      6\u001b[0m         (axs2[\u001b[38;5;241m1\u001b[39m], hist_HPD_delta, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHPD delta peak\u001b[39m\u001b[38;5;124m\"\u001b[39m, fit_HPD),\n\u001b[1;32m      7\u001b[0m     ]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist_MCP_delta' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_FWHM_analysis(hist_MCP_delta=hist_MCP_delta, hist_HPD_delta=hist_HPD_delta, fit_MCP=fit_MCP, fit_HPD=fit_HPD):\n",
    "    # 2) Zoomed delta peaks with fits\n",
    "    fig2, axs2 = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    for ax, counts, title, fit in [\n",
    "        (axs2[0], hist_MCP_delta, \"MCP delta peak\", fit_MCP),\n",
    "        (axs2[1], hist_HPD_delta, \"HPD delta peak\", fit_HPD),\n",
    "    ]:\n",
    "        ax.step(centers_delta, counts, where='mid', label='Histogram')\n",
    "        if fit is not None:\n",
    "            # smooth x for fitted curve\n",
    "            xfit = np.linspace(fit['x'][0], fit['x'][-1], 400)\n",
    "            yfit = gauss(xfit, fit['A'], fit['mu'], fit['sigma'])\n",
    "            ax.plot(xfit, yfit, 'b-', lw=2, label='Gaussian fit')\n",
    "            # FWHM lines\n",
    "            halfmax = fit['A'] * np.exp(0) * 0.5\n",
    "            # Solve for the two x at half max analytically for Gaussian:\n",
    "            dx = np.sqrt(2*np.log(2)) * fit['sigma']\n",
    "            xL, xR = fit['mu'] - dx, fit['mu'] + dx\n",
    "            ax.hlines(halfmax, xL, xR, colors='k', linestyles='--', label='FWHM')\n",
    "            ax.vlines([xL, xR], 0, halfmax, colors='k', linestyles=':')\n",
    "            ax.text(fit['mu'], halfmax, f\"FWHM = {fit['fwhm']:.3f} ns\", ha='center', va='bottom')\n",
    "            # zoom limits\n",
    "            pad = 0.5 * fit['fwhm']\n",
    "            ax.set_xlim(fit['mu'] - max(10*dx, pad), fit['mu'] + max(10*dx, pad))\n",
    "            ax.set_ylim(0, max(counts[(centers_delta>=fit['mu']-2*dx)&(centers_delta<=fit['mu']+2*dx)].max()*1.2, yfit.max()*1.2))\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"ToA ns\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b435f0d-40e6-458e-9dc9-56935e831ff7",
   "metadata": {},
   "source": [
    "### make it into one working function \n",
    "$\\Rightarrow$ rewrite the code for the full histograms and implement the functions for the fit and the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6be2248-2109-49b1-a794-2ab7e7a0d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    p = argparse.ArgumentParser(description=\"Accumulate histograms from Parquet and fit Gaussian to delta peak (FWHM)\")\n",
    "    p.add_argument(\"parquetfile\", help=\"Path to Parquet file\")\n",
    "    p.add_argument(\"--bins\", type=int, default=1000, help=\"Number of bins\")\n",
    "    p.add_argument(\"--tot_range\", nargs=2, type=float, default=[0.001, 5.0], help=\"ToT range: min max (ns)\")\n",
    "    p.add_argument(\"--delta_range\", nargs=2, type=float, default=[0.0, 20.0], help=\"Delta range: min max (ns)\")\n",
    "    p.add_argument(\"--batch\", type=int, default=500_000, help=\"Batch size for iter_batches\")\n",
    "    p.add_argument(\"--halfwidth\", type=float, default=5, help=\"Half-width (ns) of fit window around peak\")\n",
    "    p.add_argument(\"--outdir\", default=\"plots\", help=\"Output directory for figures\")\n",
    "    return p.parse_args()\n",
    "    \n",
    "def main(): # sequentially runs the different functions\n",
    "    # 1) collect arguments\n",
    "    args = parse_args()\n",
    "    \n",
    "    # 2) Run and display the full histograms\n",
    "    (centers_tot, bin_edges_tot, centers_delta, \n",
    "     bin_edges_delta, hist_MCP_tot, hist_HPD_tot, hist_trig_tot, \n",
    "     hist_MCP_delta, hist_HPD_delta, hist_trig_delta) = accumulate_full_hists(args.parquetfile, \n",
    "                                                                              num_bins = bins, \n",
    "                                                                              tot_range = tuple(tot_range),\n",
    "                                                                              delta_range = tuple(delta_range),\n",
    "                                                                              batchsize = batch)\n",
    "    plot_full(centers_tot, bin_edges_tot, centers_delta, \n",
    "              bin_edges_delta, hist_MCP_tot, hist_HPD_tot, hist_trig_tot, \n",
    "              hist_MCP_delta, hist_HPD_delta, hist_trig_delta)\n",
    "    \n",
    "    '''\n",
    "    # Fit MCP and HPD delta peaks\n",
    "    fit_MCP = fit_peak(centers_delta, hist_MCP_delta, halfwidth=halfwidth)   # tune halfwidth\n",
    "    fit_HPD = fit_peak(centers_delta, hist_HPD_delta, halfwidth=1.5)\n",
    "    \n",
    "    plot_FWHM_analysis()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "279f8919-510a-4607-965d-b5a59a5ed427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--bins BINS]\n",
      "                             [--tot_range TOT_RANGE TOT_RANGE]\n",
      "                             [--delta_range DELTA_RANGE DELTA_RANGE]\n",
      "                             [--batch BATCH] [--halfwidth HALFWIDTH]\n",
      "                             [--outdir OUTDIR]\n",
      "                             parquetfile\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2cae39-18b8-414d-aa15-e2da700572cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
